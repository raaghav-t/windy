\documentclass[11pt]{article}


% ------------------------------------------------
% Packages
% ------------------------------------------------
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage[left=0.9in,right=0.9in,top=1in,bottom=1in]{geometry}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}


\title{Dynammic Programming in Rook Endgames}
\author{Melissa Osheroff, Tien Nguyen, Raaghav Thirumaligai}
\date{\today}

\begin{document}

\maketitle

% ------------------------------------------------
% Abstract
% ------------------------------------------------
% ------------------------------------------------
% Abstract
% ------------------------------------------------
\begin{abstract}
    This project proposes the software implentation of a dynamic program that finds the best outcome for Player 1 in chess endgame. Player 1 has a rook and a king left, whereas Player 2 has only a king. Thus, this is a zero-sum game where Player 1 is trying to checkmate and Player 2 is trying to stalemate. 
\end{abstract}

% =================================================
\section{Introduction}
% =================================================

% Paragraph 1: Problem description
Brief description of the problem and context.

% Paragraph 2: Literature review (short version)
Discussion of related work and positioning within the literature.

% Paragraph 3: Contribution
The main contribution of this paper is:
\begin{itemize}
    \item Contribution 1
    \item Contribution 2
\end{itemize}

% Final paragraph: Organization
The remainder of this paper is organized as follows.
Section~\ref{sec:related} discusses related work.
Section~\ref{sec:problem} formulates the problem.
Section~\ref{sec:main} presents the main result.
Section~\ref{sec:discussion} discusses consequences.
Section~\ref{sec:proofs} provides proofs.
Section~\ref{sec:examples} presents applications.
Section~\ref{sec:conclusion} concludes the paper.

% =================================================
\section{Problem Statement}
\label{sec:problem}
% =================================================

\subsection*{System Description}
We want to find the most optimal path to winning a game of chess, given a rook(H1) and a king(A1) against a king(A8). The optimal path is defined as a checkmate occuring before stalemate for Player 1 and occurring with the least amount of moves possible.   

% =================================================
\section{Proposed Approach}
% =================================================

We propose the following steps:

\begin{enumerate}
    \item \textbf{Formal Modeling:} Define xGame in normal-form and, if appropriate, extensive-form representation. Identify strategy spaces and payoff functions.
    \item \textbf{Equilibrium Analysis:} Characterize pure and mixed Nash equilibria. Analyze existence, uniqueness, and structural properties.
    \item \textbf{Learning Dynamics:} Implement reinforcement learning agents (e.g., Q-learning or policy-gradient methods) and study convergence behavior under repeated play.
    \item \textbf{Comparative Analysis:} Compare learned strategies with theoretical equilibria and evaluate efficiency and stability.
\end{enumerate}


<<<<<<< Updated upstream
The analytical portion of the project will rely on standard results from noncooperative game theory, including Nash equilibrium existence theorems and best-response analysis. 

The computational portion will involve implementing learning algorithms in Python or MATLAB. We will simulate repeated interactions under varying initializations and learning rates. Performance metrics may include convergence speed, empirical regret, payoff efficiency, and stability of learned strategies.

% =================================================
\section{Expected Contributions}
% =================================================

We expect this project to:

\begin{itemize}
    \item Provide a rigorous mathematical formulation of xGame.
    \item Identify and characterize its equilibrium structure.
    \item Evaluate whether reinforcement learning converges to equilibrium strategies.
    \item Highlight differences between theoretical predictions and empirical learning outcomes.
\end{itemize}

% =================================================
\section{Timeline}
% =================================================

\begin{itemize}
    \item Weeks 1--2: Formal modeling and equilibrium analysis.
    \item Weeks 3--4: Implementation of learning algorithms.
    \item Week 5: Simulation experiments and comparative analysis.
    \item Final Week: Write-up and presentation preparation.
\end{itemize}

% =================================================
\section{Conclusion}
% =================================================

This proposal outlines a structured investigation of strategic interaction and adaptive learning in chess. By combining equilibrium analysis with reinforcement learning experiments, we aim to bridge theoretical game-theoretic predictions and algorithmic behavior under repeated play.
=======
>>>>>>> Stashed changes
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
