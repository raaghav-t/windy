\documentclass[11pt]{article}


% ------------------------------------------------
% Packages
% ------------------------------------------------
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage[left=0.9in,right=0.9in,top=1in,bottom=1in]{geometry}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}


\title{Project Proposal: Learning and Equilibrium Analysis in xGame}
\author{Melissa Osheroff, Tien Nguyen, Raaghav Thirumaligai}
\date{\today}

\begin{document}

\maketitle

% ------------------------------------------------
% Abstract
% ------------------------------------------------
% ------------------------------------------------
% Abstract
% ------------------------------------------------
\begin{abstract}
This project proposes to study strategic behavior and learning dynamics in xGame using tools from noncooperative game theory and reinforcement learning. We aim to formally model the game, analyze its equilibrium structure, and investigate whether learning-based agents converge to Nash equilibria under repeated play. The project will combine analytical results with computational experiments to better understand strategic adaptation and performance.
\end{abstract}

% =================================================
\section{Introduction}
% =================================================

% Paragraph 1: Problem description
Brief description of the problem and context.

% Paragraph 2: Literature review (short version)
Discussion of related work and positioning within the literature.

% Paragraph 3: Contribution
The main contribution of this paper is:
\begin{itemize}
    \item Contribution 1
    \item Contribution 2
\end{itemize}

% Final paragraph: Organization
The remainder of this paper is organized as follows.
Section~\ref{sec:related} discusses related work.
Section~\ref{sec:problem} formulates the problem.
Section~\ref{sec:main} presents the main result.
Section~\ref{sec:discussion} discusses consequences.
Section~\ref{sec:proofs} provides proofs.
Section~\ref{sec:examples} presents applications.
Section~\ref{sec:conclusion} concludes the paper.

\paragraph*{Notation}
Define notation only if widely used. Otherwise introduce symbols when needed.

% =================================================
\section{Related Work}
\label{sec:related}
% =================================================

Organize into paragraphs by topic or chronology.

Be fair and avoid overselling your contribution.

% =================================================
\section{Problem Statement}
\label{sec:problem}
% =================================================

\subsection*{System Description}
Describe the process/system and define state variables.

\subsection*{Actuation Mechanism}
Describe input/control variables and dynamics:
\begin{equation}
    \dot{x} = f(x,u,w)
\end{equation}

\subsection*{Sensing Mechanism}
Define outputs:
\begin{equation}
    y = h(x)
\end{equation}

\subsection*{Objective}
Design a controller/algorithm that achieves:
\begin{equation}
    \text{Minimize } J(x,u)
\end{equation}
subject to system constraints.

Include a figure here if helpful and refer to it explicitly.


% =================================================
\section{Proposed Approach}
% =================================================

We propose the following steps:

\begin{enumerate}
    \item \textbf{Formal Modeling:} Define xGame in normal-form and, if appropriate, extensive-form representation. Identify strategy spaces and payoff functions.
    \item \textbf{Equilibrium Analysis:} Characterize pure and mixed Nash equilibria. Analyze existence, uniqueness, and structural properties.
    \item \textbf{Learning Dynamics:} Implement reinforcement learning agents (e.g., Q-learning or policy-gradient methods) and study convergence behavior under repeated play.
    \item \textbf{Comparative Analysis:} Compare learned strategies with theoretical equilibria and evaluate efficiency and stability.
\end{enumerate}

% =================================================
\section{Methodology}
% =================================================

The analytical portion of the project will rely on standard results from noncooperative game theory, including Nash equilibrium existence theorems and best-response analysis. 

The computational portion will involve implementing learning algorithms in Python or MATLAB. We will simulate repeated interactions under varying initializations and learning rates. Performance metrics may include convergence speed, empirical regret, payoff efficiency, and stability of learned strategies.

% =================================================
\section{Expected Contributions}
% =================================================

We expect this project to:

\begin{itemize}
    \item Provide a rigorous mathematical formulation of xGame.
    \item Identify and characterize its equilibrium structure.
    \item Evaluate whether reinforcement learning converges to equilibrium strategies.
    \item Highlight differences between theoretical predictions and empirical learning outcomes.
\end{itemize}

% =================================================
\section{Timeline}
% =================================================

\begin{itemize}
    \item Weeks 1--2: Formal modeling and equilibrium analysis.
    \item Weeks 3--4: Implementation of learning algorithms.
    \item Week 5: Simulation experiments and comparative analysis.
    \item Final Week: Write-up and presentation preparation.
\end{itemize}

% =================================================
\section{Conclusion}
% =================================================

This proposal outlines a structured investigation of strategic interaction and adaptive learning in chess. By combining equilibrium analysis with reinforcement learning experiments, we aim to bridge theoretical game-theoretic predictions and algorithmic behavior under repeated play.
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
